WSIB CLAIMS and INSPECTIONS PROJECT

Current project
The current study will consider the WSIB claims, high impact claims for an industry and region combination and investigate how these related to the workplace visit findings by 
Ministry of Labour inspectors.  This project will be a first step in trying to predict the expected number of allowed time injuries made to the WSIB based on the number of 
workplace visits to a workplace in a specific region of the province and industry as well as the number of contraventions found during the visit.  Additional information about 
the labour force make up focusing on age groups, was incorporated into the data.
The current project looks to identify characteristics of employees and workplaces, and interactions which may help determine the likelihood of workers experiencing injuries 
resulting in the submission of a claim to the WSIB, specifically whether the industry or region of the workplace show any influence on the rates of claims made.   In so doing, 
the project aims to provide insight into future strategies for the ministry to better target preventative efforts and improve the safety of workplaces in Ontario.  


For each report the following filters were applied on the "Report Builder":
Injury/Illness year --> 2019
Industry Sector --> all except Schedule 2 and Unknown

Questions explored
Which industries see the highest number of claims and inspections? If differences exist, are they significant?

Are there differences between regions and industries in the number of total claims as well as rate of high impact claims significant?

Does a higher proportion of younger workers (ages 15-24) show association with higher level of claims approved by the WSIB?

When considering information about the number of workplace visits conduced by the Ministry of Labour inspectors, are any of the 
attributes included in the study suitable to help predict which industries or regions in the province of Ontario will have various levels of different types of claims?


An additional file containing the NAICS codes for each industy is also included.

DATA PREPARATION (1 Data preparation.rmd)
R code was used to prepare the data.  The code in the DataPrep.rmd file reads each data file, collapses the "Year" column, combines the files via inner join, 
checks for NA values and writes the end result.  Two files were written as a result; file contatining all three types of claims WSIB_data.csv 
(No lost time, lost time and fatality) as well as a file containing only the non-fatal claims WSIB_no_fat.csv (No lost time, lost time).

EDA(File: 2. EDA & Profile_Report.html)
The Exploratory Data Analysis report was prepared using Python.  Code for this portion is included in EDA.ipynb. 
The ProfileReport using the pandas package was prepared as WSIB_Profile_Report.
Similarily to the data files, an additional profile report was created for the data containing only non-fatal claims --> WSIB_no_fat_Profile_Report.

Data Transformations (3 Encoding)
Python code using Jupyter Notebook for the transformations was applied to the data.  Prior to any transformations, the data was first split into train/test sets using 
70/30 ratio. 

TEST FOR NORMALITY: Next the train set was tested for normality using the Shapiro-Wilk test and results for all three types of claims showed evidence that the samples are not
normally distributed (p<0.01).

DISCRETIZATION: The numeric variables were then transformed into categories using the equal-frequency method as this method is preferred for modelling.  
The number of bins for each variable was the maximum allowed by the function.  Maximum was reached when the addition of another bin would create two identical internals.

Feature Selection (file: 4. Feature Selection)
Two methods were explored and tested during training.  Since the data was categorical Chi-squared and RFE methods were applied.

CLASSIFICATION MODELs (Classification Model.ipynb)
The following three classification models were trained, and optimized.

Multinomial Logistic Regeression by claims level to form a 5x5 confusion matrix 
K Nearest Neighbours classification
Random Forest Classification 

Perform repeated  k-fold cross validation of the models
Optimization for model specific hyperparameters (eg. K in KNN, number of trees in Random Forest)


